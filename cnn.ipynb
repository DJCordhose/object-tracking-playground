{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543e26f3",
   "metadata": {},
   "source": [
    "# Predictor for content of bbox\n",
    "- what is in the box and what are the scores?\n",
    "- can be used to filter out non reasonable boxes\n",
    "- also tells us what is moving\n",
    "\n",
    "\n",
    "\n",
    "## IO\n",
    "- input \n",
    "  - low res image taken from bbox\n",
    "  - x, y, h, w of bbox\n",
    "  - distance (if available)\n",
    "- output, probas for\n",
    "   - Clear category\n",
    "   - nothing reasonable\n",
    "   - mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea122a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453599fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b951e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (30, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3e09cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xres = 32\n",
    "yres = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "519ffc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider addint residuals: https://keras.io/guides/functional_api/#a-toy-resnet-model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten\n",
    "\n",
    "image_model = tf.keras.Sequential()\n",
    "\n",
    "image_model.add(Conv2D(filters=32, kernel_size=3, activation='relu')) \n",
    "image_model.add(MaxPooling2D(pool_size=2))\n",
    "image_model.add(BatchNormalization())\n",
    "image_model.add(Dropout(0.3))\n",
    "\n",
    "image_model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "image_model.add(MaxPooling2D(pool_size=2))\n",
    "image_model.add(BatchNormalization())\n",
    "image_model.add(Dropout(0.3))\n",
    "\n",
    "image_model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "image_model.add(MaxPooling2D(pool_size=2))\n",
    "image_model.add(BatchNormalization())\n",
    "image_model.add(Dropout(0.3))\n",
    "\n",
    "image_model.add(Flatten())\n",
    "image_model.add(Dense(256, activation='relu'))\n",
    "image_model.add(BatchNormalization())\n",
    "image_model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "301a1cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"composed\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 32, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential_19 (Sequential)     (None, 256)          488064      ['image_input[0][0]']            \n",
      "                                                                                                  \n",
      " bbox_input (InputLayer)        [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " distance_input (InputLayer)    [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 264)          0           ['sequential_19[0][0]',          \n",
      "                                                                  'bbox_input[0][0]',             \n",
      "                                                                  'distance_input[0][0]']         \n",
      "                                                                                                  \n",
      " category_output (Dense)        (None, 10)           2650        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 490,714\n",
      "Trainable params: 489,754\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/guides/functional_api/\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "\n",
    "# dtypes need to match as we concatenate\n",
    "image_input = Input(shape=(xres ,yres, 1), dtype=\"float32\", name='image_input')\n",
    "bbox_input = Input(shape=4, dtype=\"float32\", name='bbox_input')\n",
    "distance_input = Input(shape=4, dtype=\"float32\", name='distance_input')\n",
    "\n",
    "# todo: other inputs might also need a bit of hidden layers (but maybe not)\n",
    "x = concatenate([image_model(image_input), bbox_input, distance_input])\n",
    "\n",
    "category_output = Dense(10, activation='softmax', name='category_output')(x)\n",
    "\n",
    "model = Model(\n",
    "    name='composed',\n",
    "    inputs=[image_input, bbox_input, distance_input],\n",
    "    outputs=[category_output]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc2b79ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf0113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
